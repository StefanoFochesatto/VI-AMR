%\documentclass[final,hidelinks,onefignum,onetabnum]{siamart250211}
\documentclass[review,hidelinks,onefignum,onetabnum]{siamart250211}

\usepackage{amsfonts,amssymb,bbold,stmaryrd,bm}

\usepackage{graphicx}
\ifpdf
  \DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}
\else
  \DeclareGraphicsExtensions{.eps}
\fi

\usepackage{tikz}
\usetikzlibrary{math,positioning}

\usepackage[T1]{fontenc}

\usepackage{pgfplots}
\usetikzlibrary{arrows}
\pgfplotsset{compat=1.16}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage{minted}
\setminted{fontsize=\small}

% Add a serial/Oxford comma by default.
\newcommand{\creflastconjunction}{, and~}

% Used for creating new theorem and remark environments
\newsiamremark{example}{Example}
\newsiamthm{conjecture}{Conjecture}

\newcommand{\RR}{\mathbb{R}}

\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\Div}{\nabla\cdot}

\newcommand{\bn}{\mathbf{n}}
\newcommand{\bq}{\mathbf{q}}

\newcommand{\bX}{\mathbf{X}}

\newcommand{\cK}{\mathcal{K}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}

\newcommand{\CG}{\text{CG}}
\newcommand{\DG}{\text{DG}}

\newcommand{\hmax}{h_{\max}}
\newcommand{\hmin}{h_{\min}}

\newcommand{\oneh}{\mathbb{1}_h}

% Optional PDF information
\ifpdf
\hypersetup{
  pdftitle={Adaptive mesh refinement for obstacle problems},
  pdfauthor={G.~Stefano Fochesatto and E. Bueler}
}
\fi

% Sets running headers as well as PDF title and authors
\headers{Adaptive mesh refinement for obstacle problems}{G.~Stefano Fochesatto and E. Bueler}

% Title.
\title{Adaptive mesh refinement for obstacle problems\thanks{Submitted to the editors DATE (draft \today).}}

% Authors: full names plus addresses.
\author{%
G.~Stefano Fochesatto\thanks{Dept.~of Mathematics and Statistics, University of Alaska Fairbanks, USA (\email{gsfochesatto@alaska.edu})}
\and
Ed Bueler\footnotemark[2]%
}

% FundRef data to be entered by SIAM
%<funding-group specific-use="FundRef">
%<award-group>
%<funding-source>
%<named-content content-type="funder-name">
%</named-content>
%<named-content content-type="funder-identifier">
%</named-content>
%</funding-source>
%<award-id> </award-id>
%</award-group>
%</funding-group>


\begin{document}

\maketitle

\begin{abstract}
Free-boundary problems posed as variational inequalities, including obstacle problems, appear in many scientific and engineering applications.  In their finite element (FE) solution, localization of the free boundary may be a primary goal, and the geometrical localization error often dominates the overall numerical error.  In this paper we implement, using the Firedrake FE library, new parallel adaptive mesh refinement strategies which generate accurate, high-resolution free boundaries through $h$-refinement.  We evaluate three approaches: \emph{(i)} a tag-and-refine unstructured dilation operator method using discrete adjacency to the free boundary, \emph{(ii)} a tag-and-refine method based on variable-coefficient diffusion, which thresholds a diffused active-set indicator function, and \emph{(iii)} a metric-based mesh adaptation method which averages an anisotropic, Hessian-derived Riemannian metric with an isotropic metric computed from the diffused indicator in \emph{(ii)}.  For \emph{(i)} and \emph{(ii)} classical \emph{a posteriori} error estimators must be added within the computed inactive sets to attain convergence.  These methods are evaluated, versus mesh complexity, by norm error and by geometrical localization using Jaccard distances for active sets.  Applications include classical Laplacian obstacle problems and a shallow ice flow problem for predicting glaciation.
\end{abstract}

\begin{keywords}
variational inequality, free boundary, obstacle problem, finite element, adaptive mesh refinement, glaciers
\end{keywords}

\begin{MSCcodes}
35J85, 35R35, 65N50
\end{MSCcodes}


\section{Introduction} \label{sec:intro}

The classical Laplacian obstacle problem \cite{KinderlehrerStampacchia1980} finds the equilibrium vertical displacement $u$ of an elastic membrane over some domain $\Omega \subset \RR^2$.  The membrane, attached with displacement $g$ at the fixed boundary $\partial\Omega$, is subjected to an applied force $f$, but it is also constrained to be above a given obstacle $\psi$.  The strong formulation is thus a complementarity problem over $\Omega$:
\begin{subequations} \label{eq:classical:ncp}
\begin{align}
  -\nabla^2 u - f \geq 0 \label{eq:classical:ncp:a} \\
  u - \psi \geq 0\\
  (-\nabla^2u - f)(u - \psi) = 0 \label{eq:classical:ncp:c}
\end{align}
\end{subequations}
From a solution of \eqref{eq:classical:ncp}, or rather of its weak form (below), we may identify the inactive and active sets, and the free boundary:
\begin{equation}
  I_u = \{x \in \Omega \,:\, u(x) > \psi(x)\}, \quad A_u = \Omega \setminus I_u, \quad \Gamma_u = \Omega \cap \partial I_u. \label{eq:classical:sets}
\end{equation}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{static/obstacle.png}
\caption{Solution, as wireframe, to a problem with a (hemi)spherical obstacle.}
\label{fig:ball}
\end{figure}

For the example shown in Figure \ref{fig:ball}, the obstacle $\psi$ is an upper hemisphere, the active set $A_u$ (white mesh) is a disc, and the free boundary $\Gamma_u$ is a circle.  Note that $u$ solves the Poisson equation $-\nabla^2u = f$ on $I_u$; this ``interior condition'' of the problem is the black mesh in the Figure.  Note that both Dirichlet ($u=\psi$) and Neumann ($\partial u/\partial n = \partial \psi/\partial n$) conditions apply along the unknown free boundary $\Gamma_u$.

Another physical interpretation of problem \eqref{eq:classical:ncp} is that $u$ models the water pressure, which cannot go below zero ($\psi=0$), in a porous dam \cite[for example]{AinsworthOdenLee1993}; see Example \ref{example:AOL}.  Section \ref{sec:app} will present a different obstacle problem application with a highly-nonlinear operator.  There the solution is the surface elevation of a glacier, which is constrained to be above the bedrock elevation on which the glacier sits.

Problem \eqref{eq:classical:ncp} has a weak formulation which is a variational inequality (VI) \cite{KinderlehrerStampacchia1980} over a Sobolev space.  Let $\Omega \subset \RR^d$ be the domain, $d\ge 1$, let $\cX=H^1(\Omega)$ \cite{Evans2010}, and suppose $\psi \in \cX \cap C(\bar\Omega)$.  Let $g:\partial \Omega\to \RR$ be continuous, with $g\ge\psi|_{\partial \Omega}$, and define
\begin{equation} \label{eq:classical:admissible}
\cK = \{u \in \cX \,:\, u \ge \psi \text{ and } u|_{\partial \Omega} = g\}
\end{equation}
as the admissible subset, which is closed and convex in $\cX$.  For $f\in L^2(\Omega)$, the VI formulation of \eqref{eq:classical:ncp} finds $u\in \cK$ so that
\begin{equation} \label{eq:classical:vi}
\int_\Omega \nabla u \cdot \nabla(v - u) \ge \int_\Omega f(v - u) \quad \text{ for all } v \in \cK.
\end{equation}

In Section \ref{sec:vifem} we will recall the theory of such VIs, and extend the theory of their finite element (FE) approximation.  We will generalize \eqref{eq:classical:vi} from elliptic bilinear forms like \eqref{eq:classical:vi} to coercive nonlinear operators over Banach spaces.  In an FE approximation of such a VI the numerical solution $u_h$ will solve the same weak form, but over a finite-dimensional admissible set constructed on a mesh $\cT_h$.  Similarly to Cea's lemma for PDEs \cite{ElmanSilvesterWathen2014}, the norm errors $\|u-u_h\|$ can be bounded \emph{a priori}, which we do by extending the Falk \cite{Falk1974} technique to nonlinear operators.  This will show how norm errors are controlled by FE space approximation properties, as usual, but subject to admissibility concerns, and with separation of active-set and inactive-set errors.

Adaptive mesh refinement (AMR) uses \emph{a posteriori} information from the numerical solution to strategically add mesh elements to increase the resolution and reduce the numerical error.  However, for VI problems the simulation goal is often the accurate approximation of the sets in \eqref{eq:classical:sets}, attainability of which is problem-dependent.

\begin{example} \label{example:notcontinuous}  Suppose $\Omega = (-1,1)$, $\psi(x)=1 - x^2$, and $g(x)=0$, but let $f$ be constant: $f(x)=\alpha$.  The exact solution $u$ of \eqref{eq:classical:vi} is now easily calculated: $u(x)=\psi(x)$ if $\alpha\le 2$ and $u(x)= 0.5 \alpha \psi(x)>\psi(x)$ if $\alpha>2$.  Thus for $\alpha \ge 2$ we have $A_u=\Omega$ and $I_u=\emptyset$, while if $\alpha<2$ then $A_u=\emptyset$ and $I_u=\Omega$.  This example shows that the sets \eqref{eq:classical:sets} are not continuous functions of the data $f$ of the problem.  An easy modification of this example shows that the sets are also not continuous functions of $\psi$.
\end{example}

The $\alpha=2$ case of Example \ref{example:notcontinuous} is \emph{degenerate} \cite{KinderlehrerStampacchia1980}, that is, the unconstrained solution happens to match the obstacle on a nonempty open set.  Usable convergence results for FE approximations of the solution-dependent sets $A_u,I_u,\Gamma_u$ will usually depend upon problem nondegeneracy, and our examples are accordingly non-degenerate.  Furthermore, the effectiveness of different AMR strategies for non-degenerate VI problems depends strongly upon the measure (area or volume) of the active and inactive sets.  This observation largely motivates the \emph{a posteriori} approaches of this paper.  For example, in certain problems, those elements which are significantly interior to the active set require no further computation or refinement.  For such problems, with examples given in Sections \ref{sec:results} and \ref{sec:app}, if a solution is desired at higher resolution within the active set then this can be computed in post-processing by arbitrary interpolation of the obstacle data $\psi$.

\begin{example} \label{example:activesets} Examples in Section \ref{sec:results} include three classical obstacle problems over square domains, and Figure \ref{fig:activesizes} shows their active sets in black.  For the left-hand problem, with a small active set and a long free boundary, our AMR methods refine a large fraction of the elements, namely the many elements which are close to the free boundary.  The middle problem has a known exact solution; Example \ref{example:ball} shows convergence rates.  For the right-hand problem, a clear performance benefit of our techniques, relative to uniform refinement, comes from avoiding refinement in the active set, an efficiency also exploited by the glaciation application in Section \ref{sec:app}. \end{example}

\begin{figure}[ht]
\noindent \hspace{-1mm} \mbox{\includegraphics[width=0.32\textwidth]{static/spiral.png} \, \includegraphics[width=0.32\textwidth]{static/sphere.png} \, \includegraphics[width=0.32\textwidth]{static/blisters.png}}
\caption{The area (measure) of the active set (black) can vary from small to large (left to right); the middle image matches Figure \ref{fig:ball}.}
\label{fig:activesizes}
\end{figure}

In this work we consider only $P_1$ element spaces over meshs of triangles or tetrahedra, and only $h$-refinement is addressed.  However, VIs can be solved using $p$-refinement and higher-order elements, once nontrivial penalty-type modifications are made to the VI \cite{KeithSurowiec2024}, but this is not attempted here.  Also, while the classical obstacle problem \eqref{eq:classical:vi} is equivalent to constrained minimization of a scalar objective, our analysis of FE errors for VI problems will \emph{not} require such an objective, and our refinement strategies do not exploit one if available.

Three AMR methods for VIs are introduced and detailed in Section \ref{sec:viamr}.  Our implementations use the Firedrake FE library \cite{Rathgeberetal2016} and generate conforming meshes with no hanging nodes.  The first two methods are of tag-and-refine type, only differing by which elements are tagged, with skeleton-based refinement (SBR) \cite{PlazaCarey2000} applied after tagging.  These two methods also require complementary refinement of the PDE problem in the inactive set to achieve convergence; see Section \ref{sec:inactive}.  The third method uses the Netgen and Animate \cite{Wallworketal2020} libraries for goal-oriented, metric-based mesh adaptation.  Here is a high-level view of the new methods:

\smallskip
\begin{itemize}
\item[UDO:] The unstructured dilation operator method discretely identifies elements adjacent to the computed free boundary, employing a graph-based approach to tag neighboring elements for refinement.  It generalizes the image processing operation of dilation \cite{Pratt1991} to unstructured meshes.
\item[VCD:] The variable-coefficient diffusion method starts from a node-wise indicator function for the current computed active set.  This indicator becomes the initial iterate in a single step of a time-dependent heat equation problem, which smooths the indicator about the free boundary.  This smoothed indicator is then thresholded for element tagging and refinement.
\item[AVM:] The averaged-metric method computes an intermediate representation of the size, shape, and orientation of a new mesh, namely as a tensor-valued Riemannian metric \cite{Alauzet2010}.  Here the metric is an average of an anisotropic metric, from the Hessian of the computed solution \cite{Wallworketal2020}, and an isotropic metric derived from the diffused active set indicator of the above VCD method.  This method can maintain mesh complexity as it simultaneously resolves the free boundary and reduces errors in the inactive set.
\end{itemize}

\smallskip
Note that the UDO and VCD methods generally produce similar results, but their motivation, and their control parameters, are sufficiently different to justify separate presentation.

Example meshes are shown in Figure \ref{fig:threeballmeshes}, generated by three levels of refinement using the above three methods, starting from a coarse uniform mesh, on the obstacle problem shown in Figure \ref{fig:activesizes} (middle).  All three schemes quickly concentrate effort around an accurately-localized free boundary, augmented by refinement as needed in the inactive set (Section \ref{sec:inactive}).  This kind of AMR accelerates convergence and reduces unnecessary computation.

% result from examples/sphere.py; note: -n 1 UDO; default VCD; default AVM; theta=0.7 in BR
\begin{figure}[ht]
\noindent \hspace{-1mm} \mbox{\includegraphics[width=0.32\textwidth]{static/sphereudo.png} \, \includegraphics[width=0.32\textwidth]{static/spherevcd.png} \,\,\includegraphics[width=0.32\textwidth]{static/sphereavm.png}}
\caption{Meshes from UDO (left), VCD (middle), and AVM (right) methods.}
\label{fig:threeballmeshes}
\end{figure}

AMR for VI problems has only been lightly explored in the literature.  The first published analysis may be \cite{AinsworthOdenLee1993}, giving an error bound for the classical obstacle problem in terms of local functionals associated with each element.  The monograph by Suttmeier \cite{Suttmeier2008} covers a broader class of problems, including elasticity.  For the classical obstacle problem, the constructable error estimators in these works require heuristic assumptions which may not hold in general.  (See inequality (42) in \cite{AinsworthOdenLee1993}, and the approximation ``$(u-\psi)\lambda_h\approx 0$'' in \cite{Suttmeier2008}.)  To our knowledge these approaches are not found in publicly-available implementations, nor are they as efficient as our strategies for computing high-resolution approximations to free boundaries.

Our focus in this paper is on AMR performance, not solver performance.  For all examples we used a fixed, VI-adapted, reduced-space Newton method with line search \cite{BensonMunson2006}, implemented in PETSc \cite{petsc-user-ref}.  Note that since the constraint $u \geq \psi$ makes VI problems nonlinear, an iterative solver is required even if the operator is linear as in \eqref{eq:classical:vi}.  Such a numerical method cannot converge quadratically until the active and inactive sets stabilize on the given mesh.  Then convergence will occur in one additional iteration, for a linear operator, or otherwise in a few iterations for a well-behaved nonlinear operator.

In summary, here are two principles for the AMR methods of this paper:
\renewcommand{\labelenumi}{\arabic{enumi}.}
\begin{enumerate}
\item Relative to uniform refinement, they exhibit significant improvements in convergence rate.  This is measured by norms, or especially by free-boundary localization (geometrical) error (Section \ref{sec:results}),  per mesh degree of freedom.
\item Their implementations (\href{https://github.com/StefanoFochesatto/VI-AMR}{{\small \texttt{github.com/StefanoFochesatto/VI-AMR}}}) within the Firedrake \cite{Langeetal2016} FE library are parallel, well-documented, and easy-to-use.
\end{enumerate}

\smallskip
The paper is organized as follows:  Section \ref{sec:vifem} provides \emph{a priori} norm bounds for FE methods applied to VI problems; aspects of this material are new.  Section \ref{sec:inactive} addresses \emph{a posteriori} error estimators which can be applied in the inactive set.  Section \ref{sec:viamr} describes the three new AMR methods in more detail.  Sections \ref{sec:results} and \ref{sec:app} compare and discuss their performance on classical obstacle model problems and in a realistic glacier application.  Table \ref{tab:abbrev} states the few abbreviations used herein.

\begin{table}[ht]
\centering
\begin{minipage}[t]{0.43\textwidth}
\vspace{0pt}
{\small
\begin{tabular}{ll} \\
AMR       & adaptive mesh refinement \\
AVM$^*$   & averaged-metric \\
BR        & Babu\v{s}ka--Rheinboldt \\
CG        & continuous Galerkin \\
DG        & discontinuous Galerkin \\
FE        & finite element
\end{tabular}
}
\end{minipage}
\,
\begin{minipage}[t]{0.48\textwidth}
\vspace{0pt}
{\small
\begin{tabular}{ll} \\
GR        & gradient recovery \\
PDE       & partial differential equation \\
SBR       & skeleton-based refinement \\
UDO$^*$   & unstructured dilation operator \\
VCD$^*$   & variable-coefficient diffusion \\
VI        & variational inequality
\end{tabular}
}
\end{minipage}
\caption{Abbreviations used in this paper.  Stars indicate the new AMR methods.}
\label{tab:abbrev}
\end{table}


\section{Variational inequalities and their finite element approximations} \label{sec:vifem}

We consider unilateral obstacle problems in Banach spaces.  Let $\Omega \subset \RR^d$, $d\ge 1$, be a bounded, polygonal domain.  Let $\cX = W^{1,p}(\Omega)$, $p>1$, be the Sobolev space of measurable functions with $p$th-integrable weak gradients \cite{Evans2010}.  We will assume continuous problem data, with well-defined point values, so suppose $\psi \in \cX \cap C(\bar\Omega)$ and $g\in C(\partial \Omega)$ satisfy $g \ge \psi|_{\partial\Omega}$.  Define the closed and convex admissible subset
\begin{equation} \label{eq:admissible}
\cK = \{v \in \cX \,:\, v \ge \psi \text{ and } v|_{\partial \Omega} = g\} \subset \cX,
\end{equation}
same as in \eqref{eq:classical:admissible}.  Observe that generally $\psi\notin\cK$.

Let $\cX'$ be the dual space of $\cX$, and denote the application of $\omega \in \cX'$ to $v\in \cX$ by $\omega[v] \in \RR$.  The norm on $\cX$ is denoted $\|\cdot\|$, and for $\cX'$ the norm is $\|\omega\|' = \sup_{\|v\|=1} |\omega[v]|$.  Let $F:\cK \to \cX'$ be a given operator, generally nonlinear, and let $\ell\in \cX'$ be given.  (While $F$ in Example \ref{example:classicalobstacle} is defined on all of $\cX$, the problem in Section \ref{sec:app} shows how $F$ might be defined only on $\cK$.)  The VI associated to this data, a unilateral obstacle problem, finds $u\in \cK$ so that
\begin{equation} \label{eq:vi}
F(u)[v - u] \ge \ell[v - u] \quad \text{ for all } v \in \cK.
\end{equation}

The problems in this paper can be analyzed within the framework of coercivity and Lipschitz continuity.  We say $F$ is $q$-coercive, $1<q<\infty$, if there is $\alpha>0$ so that
\begin{equation} \label{eq:coercive}
(F(v) - F(w))[v - w] \ge \alpha \|v-w\|^q
\end{equation}
for all $v,w \in \cK$.  Note that if $F$ is $q$-coercive then it is also strictly monotone: $(F(v) - F(w))[v - w] > 0$ for $v\ne w$.  Let $B_R(0)$ be the open ball at $0\in \cX$ of radius $R>0$.  We say $F$ is Lipschitz on bounded subsets if there is $C(R)>0$ so that
\begin{equation} \label{eq:lipschitz}
\|F(v)-F(w)\|' \le C(R) \|v-w\|
\end{equation}
for all $v,w \in B_R(0)\cap \cK$.  If $F$ satisfies \eqref{eq:lipschitz} then it is continuous.  From coercivity, strict monotonicity, and continuity of $F$ it follows that a unique solution to \eqref{eq:vi} exists \cite[Corollary III.1.8]{KinderlehrerStampacchia1980}.

\begin{example}  \label{example:classicalobstacle}
In the classical obstacle problem \eqref{eq:classical:vi}, over $\cX=H^1(\Omega)=W^{1,2}(\Omega)$, $F(u)[v] = \int_\Omega \grad u\cdot \grad v\,dx$.  This bilinear operator is $2$-coercive because the Laplacian is uniformly elliptic \cite{Evans2010}, and it is Lipschitz over $\cX$ with constant $C=1$.
\end{example}

\begin{example}  \label{example:flatsia}
In the glacier model of Section \ref{sec:app}, when the bedrock is flat and the surface mass balance is independent of elevation the VI problem \eqref{eq:sia:vi} uses a $4$-Laplacian operator over transformed thicknesses $u\in\cX=W^{1,4}(\Omega)$: $F(u)[v] = \int_\Omega \Gamma |\grad u|^2\grad u\cdot \grad v\,dx$ where $\Gamma>0$ is constant.  This operator is $4$-coercive \cite[for example]{JouvetBueler2012}, and Lipschitz on bounded subsets of $\cX$.
\end{example}

Note that if the inequality constraint in \eqref{eq:vi} were absent then the residual of the solution $u$ would be zero ($F(u)-\ell=0$); this is the PDE case.  However, for VI \eqref{eq:vi} we only have that $F(u)-\ell=0$ a.e.~within an unknown inactive set $I_u$.  The residual $F(u)-\ell\in \cX'$ might be highly-irregular in the active set $A_u$, but it is nonnegative.  In fact, the following lemma states the weak complementarity property associated to obstacle problems \eqref{eq:vi}; compare strong-form complementarity \eqref{eq:classical:ncp}.

\begin{lemma} \label{lem:measure}\cite[Theorem II.6.9]{KinderlehrerStampacchia1980}.  Suppose $u\in \cK$ solves \eqref{eq:vi}.  Then $F(u)-\ell=d\mu_u$ is a positive Radon measure supported in $A_u$.  Thus for $w\in\cX$ we have
\begin{equation}
(F(u)-\ell)[w] = \int_{A_u} w\, d\mu_u. \label{eq:measure}
\end{equation}
\end{lemma}

Now let $\cT_h$ be a shape-regular mesh partition (triangulation, etc.) of $\Omega$ \cite{AinsworthOden2000,ElmanSilvesterWathen2014}.  Let $\cX_h \subset \cX \cap C(\bar\Omega)$ be a conforming finite-dimensional FE subspace over $\cT_h$.  (Our examples will be piecewise-linear over triangles and tetrahedra: $\cX_h=P_1$.)  Assume that there is $g_h\in\cX_h$ such that $g_h=g$ along $\partial \Omega$.  Let $\psi_h \in \cX_h$ be the FE obstacle, which satisfies the compatibility requirement $\psi_h \le g_h$ along $\partial\Omega$.  Define the (nonempty) FE admissible set
\begin{equation} \label{eq:fe:admissible}
\cK_h = \{v_h \in \cX_h \,:\, v_h \ge \psi_h \text{ and } v_h|_{\partial \Omega} = g_h|_{\partial\Omega}\}.
\end{equation}
Our FE method seeks $u_h\in\cK_h$ satisfying a VI problem which approximates \eqref{eq:vi}:
\begin{equation} \label{eq:fe:vi}
F(u_h)[v_h - u_h] \ge \ell[v_h - u_h] \quad \text{ for all } v_h \in \cK_h.
\end{equation}
The same argument given for \eqref{eq:vi} shows that this has a unique solution $u_h$.  Define
\begin{equation}
  I_u^h = \{x \in \Omega \,:\, u_h(x) > \psi_h(x)\}, \quad A_u^h = \Omega \setminus I_u^h, \quad \Gamma_u^h = \Omega \cap \partial I_u^h, \label{eq:fe:sets}
\end{equation}
the numerical sets corresponding to \eqref{eq:classical:sets}, defined \emph{a posteriori} from solving \eqref{eq:fe:vi}.

Because $\cK_h \subset \cX_h \subset \cX$, we might regard \eqref{eq:fe:vi} as a conforming FE method for \eqref{eq:vi}.  However, this is subtle for an obstacle problem as it depends on the relationship between $\psi$ and $\psi_h$.  If $\psi_h$ is an interpolant of $\psi$ then $\cK_h \approx \cK$ in some sense.  Actually, one should distinguish three levels of increasingly ``conforming'' admissibility:
\renewcommand{\labelenumi}{\emph{\roman{enumi})}}
\begin{enumerate}
\item $\cK_h \not \subset \cK$
\item $\cK_h \subset \cK$
\item $\cK_h = \cK \cap \cX_h$
\end{enumerate}
Ciarlet \cite[Figure 5.1.3]{Ciarlet2002} observed early on that situation \emph{i)} generally applies for an interpolated obstacle $\psi_h = \Pi_h \psi$, e.g.~for $\cX_h=P_1$ and when $\psi$ is not convex.  Situation \emph{ii)} holds when $\psi_h \ge \psi$, which can be imposed by using a monotone injection operator, e.g.~``$\psi_h = R^\oplus \psi$'' in the notation from \cite{BuelerFarrell2024}.  (For related ideas, see \cite{GraeserKornhuber2009} and the proof of Theorem 5.1.2 in \cite{Ciarlet2002}.)  The strongest condition \emph{iii)} holds if $\psi_h=\psi$ exactly, for example when $\psi=0$ in the porous dam problems considered by \cite{AinsworthOdenLee1993}, and in Section \ref{sec:app}.

In any case, the obstacle $\psi$ is given \emph{as data} for VI problem \eqref{eq:vi} over $\cK$.  As illustrated in Section \ref{sec:results}, point values of $\psi$ can be evaluated as desired to better-represent $u_h$ within the numerical active set $A_u^h$.  Over elements where there is active-set correctness, namely $K\in\cT_h$ such that $K \subset A_u \cap A_u^h$, the error $e=u-u_h=\psi-\psi_h$ can simply be regarded as unimportant.  Alternatively, the approximation $\psi_h \approx \psi$ can be improved as needed by better interpolation of the data $\psi$.  As the goal for AMR is to more-accurately solve the FE problem, refinement within a stabilized active set, once an accurate free boundary has been found, is wasted effort.

These ideas are already implicit in \emph{a priori} bounds for FE error in VI problems.  The following theorem generalizes the Falk bound \cite{Falk1974}; see also \cite[Theorem 5.1.1]{Ciarlet2002}.  It can be extended further to address $F_h\approx F$ \cite[Theorem 6.3]{Bueler2024}, but we will not need such an operator approximation for our examples.

\begin{theorem} \label{thm:genfalk}  For $1<q<\infty$, define the conjugate exponent $q'=q/(q-1)$.  Assume that $F$ is $q$-coercive and Lipschitz on bounded subsets of its domain.  Suppose $u\in\cK$ solves \eqref{eq:vi} and $u_h\in\cK_h$ solves \eqref{eq:fe:vi}.  Let $R_h=\max\{\|u\|,\|u_h\|\}$.  Then there is a constant $c(R_h)>0$, not otherwise depending on $u$ or $u_h$, so that
\begin{align}
\|u-u_h\|^q &\le \frac{2}{\alpha} \bigg( \inf_{v\in\cK} \int_{A_u} (v-u_h)\,d\mu_u + \inf_{v_h\in\cK_h} \int_{A_u} (v_h-\psi)\,d\mu_u  \label{eq:falk} \\
   &\qquad\quad + c(R_h) \inf_{v_h\in\cK_h} \|v_h - u\|^{q'}\bigg). \notag
\end{align}
\end{theorem}

\begin{proof}
For arbitrary $v\in\cK$ and $v_h\in\cK_h$, rewrite \eqref{eq:vi} and \eqref{eq:fe:vi} as $F(u)[u] \le F(u)[v] + \ell[u-v]$ and $F(u_h)[u_h] \le F(u_h)[v_h] + \ell[u_h-v_h]$, respectively.  It follows from these inequalities, and $q$-coercivity of $F$, that
\begin{align}
\alpha \|u-u_h\|^q &\le \left(F(u)-F(u_h)\right)[u-u_h] \label{eq:falkdance} \\
  &= F(u)[u] + F(u_h)[u_h] - F(u)[u_h] - F(u_h)[u] \notag \\
  &\le F(u)[v] + \ell[u-v] + F(u_h)[v_h] + \ell[u_h-v_h] \notag \\
  &\qquad - F(u)[u_h] - F(u_h)[u] \notag \\
  &= F(u)[v-u_h] - \ell[v-u_h] + F(u_h)[v_h-u] - \ell[v_h-u] \notag \\
  &= \left(F(u)-\ell\right)[v-u_h] + \left(F(u)-\ell\right)[v_h-u] \notag \\
  &\qquad + \left(F(u)-F(u_h)\right)[u-v_h] \notag
\end{align}
Since $u,u_h\in B_{R_h} = \{w\in\cX\,:\,\|w\|\le R_h\}$, by the Lipschitz assumption \eqref{eq:lipschitz} there is $C(R_h)>0$ so that the last term from \eqref{eq:falkdance} has bound
\begin{equation}
\left(F(u)-F(u_h)\right)[u-v_h] \le C(R_h) \|u-u_h\|\|u-v_h\|. \label{eq:falklip}
\end{equation}
Now use Young's inequality with $\eps>0$ \cite[Appendix B.2]{Evans2010} on \eqref{eq:falklip}.  We have:
\begin{align}
\alpha \|u-u_h\|^q &\le \left(F(u)-\ell\right)[v-u_h] + \left(F(u)-\ell\right)[v_h-u]  \label{eq:falkyoung} \\
  &\qquad + C(R_h) \left(\eps\|u-u_h\|^q + \tilde C(\eps) \|u-v_h\|^{q'}\right) \notag
\end{align}
where $\tilde C(\eps) = (\eps q)^{-q'/q} {q'}^{-1}$.  Choose $\eps>0$ so that $C(R_h) \eps \le \alpha/2$.  Then
\begin{equation} \label{eq:falkalmost}
\frac{\alpha}{2} \|u-u_h\|^q \le \left(F(u)-\ell\right)[v-u_h] + \left(F(u)-\ell\right)[v_h-u] + C(R_h) \tilde C(\eps) \|u-v_h\|^{q'}
\end{equation}
Apply Lemma \ref{lem:measure} and take infimums to show \eqref{eq:falk}.
\end{proof}

Consider the unconstrained PDE case of \eqref{eq:falk}, namely when $A_u=\emptyset$.  In this case the bound is simply Cea's lemma (quasi-optimality) for $q$-coercive operators: $\|u-u_h\| \lesssim \inf_{v_h\in\cK_h} \|v_h - u\|^{1/(q-1)}$.  It is standard in FE theory \cite{AinsworthOden2000,ElmanSilvesterWathen2014} to address this bound by solution regularity and interpolation theory.

If $\psi_h\ge \psi$ then $\cK_h\subset \cK$, and so the first term on the right of \eqref{eq:falk} can be replaced by zero.  In this case bound \eqref{eq:falk} adds a single term to Cea's lemma, which is nonzero when $v_h\in\cK_h$ is blocked by $\psi_h$ from descending close to the continuum obstacle $\psi$ in the active set $A_u$.  Thus this term is large if $\psi_h$ is substantially above $\psi$ in $A_u$, or if $d\mu_u$ is large in $A_u$.  However, if the FE method has generated a numerical active set which is accurate, $A_u^h\approx A_u$, the errors in the active set are irrelevant because the data $\psi$ is available to the solver.

\emph{A priori} error bound \eqref{eq:falk} is further clarified in the $p=2$ and $q=q'=2$ case, the classical obstacle problem.  The bound can then be split between integrals over the (exact) active set and inactive sets.

\begin{corollary} \label{cor:falktwo}
Suppose all the hypotheses of Theorem \ref{thm:genfalk}.  Assume that $p=q=2$, and that $\psi \in C^1(\Omega)$.  Up to constants which depend on $u$ and $u_h$, we may write the \emph{a priori} bound with four integrals,
\begin{align}
\|u-u_h\|^2 \lesssim &\inf_{v\in\cK} \int_{A_u} (v-u_h)\,d\mu_u + \inf_{v_h\in\cK_h} \int_{A_u} (v_h-\psi)\,d\mu_u \label{eq:falktwo} \\
&\, + \inf_{v_h\in\cK_h} \left(\int_{A_u} |\grad v_h - \grad \psi|^2\,dx + \int_{I_u} |\grad v_h - \grad u|^2\,dx\right) \notag
\end{align}
\end{corollary}

\begin{proof}
Apply Poincare's inequality to the final term in \eqref{eq:falk}.
\end{proof}

Consider the first two integrals in bound \eqref{eq:falktwo} from the point of view of AMR.  Their size is determined partly by the action of $F$ on the continuum obstacle, and partly by the source term $\ell$.  However, because they are over the active set $A_u$, neither integral, nor the third $A_u$ integral, requires mesh refinement so as to improve the quality of the FE solution, \emph{as long as the mesh and solver have accurately located the free boundary}.  This observation suggests why the primary goal of AMR for VIs should be to generate close approximation $\Gamma_u^h\approx \Gamma_u$.  Computation expended on better approximation of the data $\psi$ in $A_u$ can be avoided if the free boundary is accurately resolved.  This is easiest to exploit within the class of unilateral obstacle problems described in Appendix \ref{app:blistering}, which includes the $\psi=0$ case of the classical obstacle problem \eqref{eq:classical:vi} and the glacier problem of Section \ref{sec:app}.  In such problems one may preprocess the data, noting all the areas where the source term is negative, and then systematically avoid unnecessary active set refinement.

However, in order for $\Gamma_u^h\approx \Gamma_u$ to be an accurate approximation, the interior condition of the VI, over $I_u$, must be accurately solved.  (This gives the significance of the final integral in \eqref{eq:falktwo}.)  Our AMR approaches will systematically refine on both sides of the computed free boundary $\Gamma_u^h$, and generally in the inactive set $I_u^h$.


\section{\emph{A posteriori} error estimation in the inactive set} \label{sec:inactive}

For $u\in\cX$ solving VI \eqref{eq:vi}, an interior condition PDE holds in the inactive set $I_u$ \cite{KinderlehrerStampacchia1980}.  Our AMR strategies (Section \ref{sec:viamr}) do \emph{a posteriori} refinement in the geometric vicinity of the free boundary, but we will also need to exploit \emph{a posteriori} error indicators for the interior condition to achieve convergence.  We consider two such PDE-type indicators.

\begin{example}  \label{example:gradrecovery}  Suppose $\cX_h=\CG_k$ is the continuous, piecewise-polynomial FE space of degree $k$, and consider $u_h\in\cX_h$.  Noting $\grad u_h$ is discontinuous, but well-defined on each element, define $\cY_h=\DG_{k-1}$ for the (scalar) discontinuous space with polynomial degree $k-1$, so that $\grad u_h \in \cY_h^d$.  Suppose there is a linear operator $G : \cX_h \to \cX_h^d$, into the continuous space, called \emph{gradient recovery} (GR) \cite[Chapter 4]{AinsworthOden2000}, so that $G(u_h)\approx \grad u_h$ in some sense.  Over an element $K \in\cT_h$, the corresponding error indicator $\eta_K\ge 0$ is then
\begin{equation} \label{eq:gradrecoveryindicator}
\eta_K^2 = \int_K \left|G(u_h) - \grad u_h\right|^2.
\end{equation}
We also define $\eta^2 = \sum_{K\in\cT_h} \eta_K^2$.  For certain gradient recovery methods $G$, when they are applied to the Poisson equation, we find that $\eta \sim |u-u_h|_{H^1}$ (energy norm) as $h\to 0$ \cite[Theorem 4.4]{AinsworthOden2000}.
\end{example}

Our application of GR in Section \ref{sec:app} will simply use orthogonal projection in $L^2$ for the map $G$.  That is, $G(u_h) \in \cX_h^d$ is defined to be the minimizer of
\begin{equation} \label{eq:gradrecoveryprojection}
J(w) = \int_\Omega |w - \grad u_h|^2\,dx.
\end{equation}
In this application $\cX_h = \CG_1$, $\grad u_h$ is in vector-valued $\DG_0$, and $G(u_h)$ is in $\cX_h^d$.

The second indicator, applied in Section \ref{sec:results} to classical problem \eqref{eq:classical:vi}, is a well-known \emph{explicit error estimator} \cite[Chapter 2]{AinsworthOden2000}.

\begin{example}  \label{example:br}  Suppose $u \in H^1(\Omega)$ solves the weak form Poisson equation $a(u,v) = \int_\Omega f v\,dx$ for all $v \in H^1_0(\Omega)$, with $a(u,v)=\int_\Omega \grad u\cdot \grad v\,dx$ and $u=g$ on $\partial \Omega$.  Suppose that $u_h\in\cX_h=\CG_1$ solves the corresponding finite-dimensional weak form.  For each element $K \in \cT_h$, define $n_K$ as the unit outward normal vector on $\partial K$.  For a pair of elements $L,K$ incident to an edge $\gamma$, and any vector field $Z$ with traces $Z_L,Z_K$ on $\gamma$, let $\left\llbracket Z \cdot n \right\rrbracket = Z_L \cdot n_L + Z_K \cdot n_K$ be the jump of $Z$ on $\gamma$.  Given the (strong) residual $r(u_h)=-\nabla^2 u_h - f$ of the Poisson equation, well-defined within each element $K$, the Babu\v{s}ka--Rheinboldt (BR) \cite{BabuskaRheinboldt1979} error estimator is
\begin{equation} \label{eq:brestimator}
\eta_K^2 = h_K^2 \int_K |r(u_h)|^2\,dx + \frac{h_K}{2} \sum_{\gamma \in \partial K \setminus \partial \Omega} \int_{\gamma} \left\llbracket \grad u_h \cdot n \right\rrbracket^2\,dS,
\end{equation}
where $h_K$ is the diameter of $K$.  It can be shown \cite[Chapter 2]{AinsworthOden2000} that the energy error is bounded by $\eta^2 = \sum_{K\in\cT_h} \eta_K^2$:
\begin{equation} \label{eq:brbound}
|u-u_h|_{H^1}^2 = \int_\Omega |\grad(u-u_h)|^2\,dx \le C \eta^2.
\end{equation}
Similarly the $L^2$ error can be bounded by an estimator, which replaces the powers in \eqref{eq:brestimator} by $h_K^4,h_K^3$, respectively \cite[Section 2.4]{AinsworthOden2000}.
\end{example}

For the results in Sections \ref{sec:results} and \ref{sec:app}, whether $\eta_K$ is computed as in Example \ref{example:gradrecovery} or \ref{example:br}, we will treat the values $\eta_k$ as local element-wise error estimators.  The set $\{\eta_K\}$ will be thresholded to providing tagging of elements for refinement; see \cite[Section 4.2]{BangerthRannacher2003} for a discussion of techniques.  In our applications, all (computed) inactive elements satisfying $\eta_K \ge \theta \max \eta_K$, for $0<\theta<1$, will be tagged and refined.

The BR error estimator for the interior condition is explicit and easily-computed.  Ainsworth, Oden, and Lee \cite{AinsworthOdenLee1993} extend it to certain obstacle problems, but with heuristic aspects.  On the other hand, for certain PDE problems, alternative estimators are provided by the \emph{dual weighted residual} technique \cite{BangerthRannacher2003}.  These are defined using a particular quantity of interest and some approximately-computed nonlocal weights, essentially Green's functions of the adjoint PDE.  Suttmeier \cite{Suttmeier2008} has extended this weighted residual technique to certain VI problems, but it also requires heuristic steps even for the classical obstacle problem.  In this paper we avoid the complexity of such techniques, and instead take a pragmatic approach which combines refinement near a computed free boundary with application of a PDE-type error estimator, as above, within the computed inactive sets.


\section{New adaptive mesh refinement strategies} \label{sec:viamr}

Our first two adaptive mesh refinement (AMR) methods, Algorithms \ref{alg:udo} and \ref{alg:vcd}, do targeted refinement near the free boundary.  They are of \emph{tag-and-refine} type.  The third \emph{metric-based mesh adaptation} approach \cite{Wallworketal2020}, Algorithm \ref{alg:avm}, is more expensive.

These methods all start from a computed solution $u_h \in \cK_h \subset \cX_h$ to problem \eqref{eq:fe:vi}.  Specifically we need only the mesh $\cT_h$, the obstacle $\psi_h \in \cX_h$, and $u_h$.  The following two concepts are fundamental.

\begin{definition} \label{def:nodalactive}
Denote the vertices of $\cT_h$ by $x_j$.  Given $u_h \ge \psi_h$ and a tolerance $\text{tol}>0$, the \emph{nodal active set indicator} is the unique $\nu_h\in\cX_h$ satisfying
	$$\nu_h(x_j) = \begin{cases} 1, & u_h(x_j) - \psi_h(x_j) < \text{tol} \\
	                             0, & \text{otherwise.}\end{cases}$$
\end{definition}

\begin{definition} \label{def:marking}
An \emph{element marking} of $\cT_h$ is a piecewise-constant indicator function $\oneh \in \DG_0(\cT_h)$ with values in $\{0,1\}$.
\end{definition}

For PDE problems,and element marking can be derived from an error estimator $\eta_K$, as in the previous Section, associated with a quantity of interest such as energy or $L^2$ norm error \cite{BangerthRannacher2003}.  However, a primary quantity of interest for obstacle problems is \emph{vicinity to the unknown free boundary}.  We do not associate this concept with a precise functional.  Instead Algorithms \ref{alg:udo} and \ref{alg:vcd} proceed heuristically to convert a nodal active set indicator into an element marking, with the goal of improving the approximation of the free boundary.

Queries of PETSc DMPlex objects \cite{Langeetal2016} will also be needed, so let us sketch how this class supports unstructured meshes.  A DMPlex object stores the topology (connectivity) of a dimension $d=1,2,3$ mesh.  Every mesh entity, regardless of dimension, is assigned a unique index.  Mesh connectivity is understood as a stratified directed acyclic graph, where a covering/incidence relationship between mesh entities determines the graph edges.  For example, a triangle within a 2D mesh is covered by its three edges, which are covered by their two endpoints (vertices).  Each stratum (``height'') in the DAG represents a dimensional class of mesh entity; for example the cells, edges, and vertices in a 2D mesh are at heights $0$, $1$, $2$.  Given the index $p$ of a mesh entity, the basic DMPlex queries \cite{petsc-user-ref} are $\text{\emph{cone}}(p)$, the set of indices of entities which cover entity $p$, and its dual $\text{\emph{support}}(p)$, the set of entities which are covered by $p$.  The transitive closure of \emph{cone} is $\text{\emph{closure}}(p)$, and that of \emph{support} is $\text{\emph{star}}(p)$.  In our application we need only the vertices in the element closure; we denote this as $\text{\emph{closure}}^\wedge(k)$.  Similarly, $\text{\emph{star}}_\vee(j)$ extracts only elements in the star of vertex $x_j$.

Now we can define the Unstructured Dilation Operator (UDO) method, Algorithm \ref{alg:udo}.  It first computes a nodal active set indicator $\nu_h$ from $u_h$.  Denoting the degrees of freedom in $\DG_0(\cT_h)$ by $x_k$, it then finds the set of indices $k$ of elements such that $0<\nu_h(x_k)<1$.  If $u_h \in \CG_1$ then this condition holds when the element is incident to both active and inactive vertices.  Then the method alternates closure and star on the marked element set $n$ times, expanding the marking by $n$ element layers, to generate a final element marking $\oneh$.  The motivation here is that if the approximation $u_h\approx u$ is good for a non-degenerate VI problem \eqref{eq:vi} then the true free boundary $\Gamma_u$ should pass through the elements indicated \emph{a posteriori} by $\oneh$.  In Sections \ref{sec:results} and \ref{sec:app} we will only consider $n=1,2$, as this much expansion seems to suffice for accurate representation of the free boundary after a few refinements.

\begin{algorithm}[ht]
	\caption{Unstructured Dilation Operator (UDO) element marking}
	\begin{algorithmic}[1]
		\Require mesh $\cT_h$, solution $u_h \in \cK_h$, obstacle $\psi_h \in \cX_h$, tolerance $\text{tol} > 0$, and expansion parameter $n\ge 1$.
		\State Compute nodal active set indicator $\nu_h \in \cX_h$ for $u_h$.
		\State Find initial element index set $S_0$: \,$k\in S_0$ if $\nu_h(x_k) \in (0,1)$.
		\For{$i=0,\dots,n-1$}
		    $$S_{i+1} = \bigcup_{k\in S_i}\, \bigcup_{j\in \text{\emph{closure}}^\wedge(k)} \text{\emph{star}}_\vee(j)$$
		\EndFor \\
		\Return marking $\oneh \in \DG_0(\cT_h)$ of all elements with indices in $S_n$.
	\end{algorithmic}
\label{alg:udo}
\end{algorithm}

While the UDO strategy explicitly manipulates indices, our second strategy, called Variable Coefficient Diffusion (VCD), Algorithm \ref{alg:vcd}, is based on continuum ideas.  Again the first step is to compute a nodal active set indicator $\nu_h \in \CG_1$.  This function is used as the initial condition of a time-dependent, variable-coefficient diffusion equation,
\begin{equation} \label{eq:diffusioneqn}
\frac{\partial s}{\partial t} = \Div\left(D \grad s\right), \qquad s(t=0) = \nu_h,
\end{equation}
with Neumann (natural) boundary conditions, a well-posed problem.  Clearly a solution of \eqref{eq:diffusioneqn} at $t>0$ is a smoothed form of $\nu_h$.  The diffusivity is set to the square of the element diameter $h_K$, namely $D=C h_K^2 \in \DG_0$, with $C=0.5$ by default.  The diffusion range is thus proportional to element diameter.  In fact \eqref{eq:diffusioneqn} is not solved exactly, or even very accurately, as we only compute $s_h\in\cX_h$ from a single backward-Euler step of duration $\Delta t = 1$, equation \eqref{eq:bestep} below.  The default solver for this linear and elliptic problem is four iterations of conjugate gradient, preconditioned by incomplete-Cholesky factorization \cite{Bueler2021}.  This inexpensive approximate solver has linear complexity in the vertices.

\begin{algorithm}[ht]
	\caption{Variable Coefficient Diffusion (VCD) element marking}
	\begin{algorithmic}[1]
		\Require mesh $\cT_h$, solution $u_h \in \cK_h$, obstacle $\psi_h \in \cX_h$, tolerance $\text{tol} > 0$, and threshold interval $0 < \alpha < \beta < 1$.
		\State Compute nodal active set indicator $\nu_h \in \cX_h$ for $u_h$.
		\State For $h_K$ the element diameter, let $D=0.5 h_K^2 \in \DG_0(\cT_h)$.
		\State Approximately solve for $s_h\in\cX_h$, with natural boundary conditions:
		\begin{equation} \label{eq:bestep}
            s_h - \Div(D \grad s_h) = \nu_h
		\end{equation}
		\Return marking $\oneh \in \DG_0(\cT_h)$ of all elements such that $s_h(x_k) \in (\alpha,\beta)$.
    \end{algorithmic}
\label{alg:vcd}
\end{algorithm}

Figure \ref{fig:vcdillustration} illustrates how the VCD algorithm applies to a one-dimensional obstacle problem.  Note that the thresholds $\alpha$ and $\beta$ are key parameters, with defaults $\alpha=0.2$ and $\beta=0.8$.  Lowering $\alpha$ toward zero expands the marking further into the inactive set, away from the (computed) free boundary, while increasing $\beta$ toward one expands further into the active set.

\begin{figure}[ht]
\input{tikz/vcdfour.tex}
\caption{Illustration of VCD: \emph{(a)} Numerical solution $u_h$ (solid), with nodes $x_j$ shown (solid dots), and obstacle $\psi_h$ (red dashed).  \emph{(b)} Nodal active set indicator $\nu_h \in \CG_1(\cT_h)$.  \emph{(c)} Smoothed indicator $s_h$, with element degrees of freedom $x_k$ (circles) and thresholding levels (red).  \emph{(d)} Element marking $\oneh$; here 4 elements are marked for refinement.}
\label{fig:vcdillustration}
\end{figure}

It turns out to be helpful, e.g.~when solving the highly-nonlinear obstacle problem in Section \ref{sec:app}, to add a minimum element diameter $\hmin$ to Algorithms \ref{alg:udo} and \ref{alg:vcd}.  That is, after running one of the above Algorithms, we may un-set the element marking, $\oneh|_K=0$, of any element with $h_K < \hmin$.

From an element marking $\oneh$ we then apply \emph{skeleton-based refinement} (SBR) \cite{PlazaCarey2000} to generate a refined mesh.  Elements with $\oneh=1$ are refined, and any other elements as needed to avoid hanging nodes.  Two SBR implementations are available, namely from PETSc DMPlex \cite{petsc-user-ref} and from the Netgen library \cite{Betteridgeetal2024}.  Only the latter is currently capable of 3D refinement.

Our third AMR method, called \emph{averaged-metric} (AVM; Algorithm \ref{alg:avm}), uses metric-based mesh adaptation \cite{Alauzet2010}.  In contrast to tag-and-refine methods, mesh adaptation generates a new mesh matching resolution and complexity targets.  Adaptation is driven by an \emph{a posteriori} metric ﬁeld, defined as a continuous, matrix-valued function $M_h:\Omega \to \RR^{d\times d}$ with each value $M_h(x)$ a symmetric and positive-definite matrix.  Such a metric contains local information on distances, areas, and volumes \cite{LoseilleAlauzet2011}.  From the metric the mesher itself generates a unit mesh \cite{Alauzet2010}.  In the original space the refined mesh has variable edge lengths and element aspect ratios.

AVM again starts from $u_h$ and $\psi_h$.  The first metric is isotropic, and it is computed from the gradient of a smoothed nodal active set indicator, namely $s_h$ from the VCD method (Algorithm \ref{alg:vcd}).  The second metric is anisotropic, computed as an approximate Hessian of $u_h$ via a Hessian-recovery technique \cite{Alauzet2010}.  (Actually the absolute value of the Hessian is used, which well-defined for a symmetric matrix \cite{Wallworketal2020}.)  These metrics are in the matrix-valued $\CG_1$ FE space, with metric normalization constants computed from target complexity and element diameter bounds in a standard manner \cite{Wallworketal2020}.  By construction, the first metric should generate small elements near the free boundary, while the second should reduce FE approximation error in the inactive set, according to the standard interpolation theory \cite{Ciarlet2002}.  In AVM the final metric is a weighted average of the two metrics.  This final metric is both anisotropic and free-boundary focussed, and it implies refinement in both the active and inactive sets.  Our implementation calls the Animate library (\href{https://github.com/mesh-adaptation/animate}{{\small \texttt{github.com/mesh-adaptation/animate}}}) to construct, normalize, and average the metrics, and the Pragmatic library \cite{Gormanetal2012} for meshing at the last step.  Note that steps 2 and 3 in Algorithm \ref{alg:avm} use the target complexity and element diameter bounds parameters.

\begin{algorithm}[ht]
	\caption{Averaged-metric (AVM) mesh adaptation}
	\begin{algorithmic}[1]
		\Require mesh $\cT_h$, solution $u_h \in \cK_h$, obstacle $\psi_h \in \cX_h$, target complexity $N$, element diameter bounds $0<\hmin<\hmax$, and averaging weight $0\le \gamma \le 1$
		\State Compute $s_h \in \cX_h$ from Algorithm \ref{alg:vcd}, using $u_h$ and $\psi_h$.
		\State Compute normalized isotropic free-boundary metric: $M_1(x)=c_1 |\grad s_h(x)| I_{d\times d}$.
		\State Compute normalized anisotropic metric from Hessian: $M_2(x)=c_2 |H u_h(x)|$.
		\State Average the metrics: $M(x) = \gamma M_1(x) + (1-\gamma) M_2(x)$. \\
		\Return new mesh $\tilde \cT_h$ which is unit with respect to $M(x)$.
    \end{algorithmic}
\label{alg:avm}
\end{algorithm}

The right-hand image in Figure \ref{fig:threeballmeshes} (Introduction) shows an AVM result on the ``ball'' obstacle problem; see Figure \ref{fig:activesizes}, middle.  Note that iterating the AVM method, even while holding the target mesh complexity constant, can be worthwhile because the increased resolution near the free boundary allows the \emph{a posteriori} metric to become more effective.  A key idea when iterating AVM is that cross-mesh interpolation \cite{Farrelletal2009} provides a high-quality initial iterate on the new mesh.  Because of the nontrivial computations needed in metric-based methods \cite{Alauzet2010,Wallworketal2020}, at high resolution one AVM iteration is notably more expensive than an iteration of UDO or VCD.

All three Algorithms run in parallel under the MPI protocol used by Firedrake \cite{Langeetal2016} and PETSc.  However, only UDO produces results which are independent of the number of processes.  The default preconditioned Krylov solver in VCD is slightly-dependent on process count \cite{Bueler2021}.  Choosing a direct solver for problem \eqref{eq:bestep} would give the VCD method process-independence, but it would also reduce scalability.

We end this Section with two Python examples which illustrate how to use the open source VIAMR library (\href{https://github.com/StefanoFochesatto/VI-AMR}{{\small \texttt{github.com/StefanoFochesatto/VI-AMR}}}).

\begin{example} \label{example:AOL}
Consider Example 1 from \cite{AinsworthOdenLee1993}, a classical obstacle problem over a rectangle, with obstacle $\psi=0$ and a known exact solution.  The code below applies the Firedrake and VIAMR libraries to solve this problem.  First it generates a uniform coarse mesh, then it applies VCD marking near the free boundary, and then it refines to a new mesh (Figure \ref{fig:resultAOL}).  There is no refinement in the inactive set, which is necessary for convergence; compare Example \ref{example:hybrid}, and see the next Section.
\inputminted[linenos, frame=lines]{python}{../examples/aol.py}
\end{example}

\begin{figure}[ht]
\centering
\mbox{\includegraphics[width=0.19\textwidth]{static/aol-mesh.png} \qquad\qquad
\includegraphics[width=0.19\textwidth]{static/aol-marked.png} \qquad\qquad
\includegraphics[width=0.19\textwidth]{static/aol-refinedmesh.png}}
\caption{The Python code in Example \ref{example:AOL} solves Example 1 from \cite{AinsworthOdenLee1993}: initial mesh (left), marking by the default-parameter VCD scheme (middle), and the refined mesh (right).  The exact free boundary, unknown to the algorithm, is overlaid in black.}
\label{fig:resultAOL}
\end{figure}

\begin{example} \label{example:hybrid}
The following snippet was used for the left-hand mesh in Figure \ref{fig:threeballmeshes}:
\begin{minted}[linenos, frame=lines]{python}
amr = VIAMR()
fbmark = amr.udomark(uh, psih, n=1)
residual = -div(grad(uh))
imark, _, _ = amr.brinactivemark(uh, psih, residual, theta=0.7)
mark = amr.unionmarks(fbmark, imark)
refinedmesh = amr.refinemarkedelements(mesh, mark)
\end{minted}
Here the UDO method is used to mark near the free boundary, then the BR error indicator (Section \ref{sec:inactive}), from a computed element-wise residual, is applied for marking in the inactive set.  Finally the marks are unioned and a new mesh is generated.
\end{example}


\section{Results on classical obstacle problems} \label{sec:results}

We start this Section with a revised look at how numerical errors should be measured for obstacle problems, and then we show convergence and performance results on some examples.  Section \ref{sec:app} will show results for a more-challenging, non-classical obstacle problem.

In order to measure the quality of the approximate sets \eqref{eq:fe:sets}, versus the exact sets \eqref{eq:classical:sets}, and to determine rates of geometric convergence, the VIAMR library computes a distance between sets.  Our implementation of \eqref{eq:jaccard} below is based on Firedrake's supermesh concept \cite{Farrelletal2009}, so it is computable for sets $S,T$ which are unions of elements from different meshes, and/or for sets defined by algebraic (conditional) expressions in the mesh coordinates.

\begin{definition} \label{def:jaccard}
The \emph{Jaccard distance} \cite{LevandowskyWinter1971} between measurable sets $S,T \subset \Omega$ is
\begin{equation}
d(S,T) = 1 - \frac{|S \cap T|}{|S \cup T|}, \label{eq:jaccard}
\end{equation}
where $|\cdot|$ is Lebesgue measure, with $d(S,T)=0$ by definition if $|S \cup T|=0$.
\end{definition}

We will use Jaccard distance to compare active sets.  If $d(S,T)=0$ then $S$ and $T$ geometrically agree up to a set of measure zero, and for a computed active set $A_u^h$, defined by an element marking (Definition \ref{def:marking}), we will report $d(A_u^h,A_u)$ when $A_u$ is exactly known.

A second goal for numerical solutions of obstacle problems is to avoid wasted effort in the active set, once the free boundary is well-resolved.  As already discussed, if $\Gamma_u^h \approx \Gamma_u$ is a good approximation then the obstacle data itself, namely $\psi$, can be used to represent the solution in the computed active set $A_u^h$.  This motivates a definition.

\begin{definition} \label{def:preferred}
Suppose the original VI problem \eqref{eq:vi} has exact obstacle $\psi \in \cX\cap C(\bar\Omega)$.  Consider a computed solution $u_h$ to the approximating problem \eqref{eq:fe:vi}, with computed active set $A_u^h$, a union of closed elements.  We define the \emph{preferred approximation} $\tilde u_h$ as the measurable function
\begin{equation} \label{eq:preferredapprox}
\tilde u_h(x) = \begin{cases} \psi(x), & x\in A_u^h \\ u_h(x), & \text{otherwise.} \end{cases}
\end{equation}
\end{definition}

For a classical obstacle problem \eqref{eq:classical:vi}, the preferred approximation $\tilde u_h$ is in $L^2(\Omega)$.  It is generally discontinuous, even when $\cX_h=\CG_k$, thus $\tilde u_h \notin H^1(\Omega)$.  However, $\tilde u_h$ is defined \emph{without} reference to the exact solution to problem \eqref{eq:vi}; only the continuum data $\psi$ is referenced.  The $L^2$ error relative to $\tilde u_h$ has a clear decomposition over the sets defined in \eqref{eq:classical:sets} and \eqref{eq:fe:sets}:
\begin{equation}
\|u-\tilde u_h\|_2^2 = 0 + \int_{A_u\setminus A_u^h} |\psi - u_h|^2 + \int_{A_u^h\setminus A_u} |u - \psi|^2 + \int_{I_u\cap I_u^h} |u-u_h|^2.  \label{eq:preferreddecomp}
\end{equation}
The leading zero comes from the integral over $A_u\cap A_u^h$, where $u=\tilde u_h=\psi$.  The next two terms are small if the free boundary has been accurately located ($\Gamma_u^h \approx \Gamma_u$), the goal of AMR in Section \ref{sec:viamr}.  The final term is small if inactive-set refinement is effective (Section \ref{sec:inactive}).  The next example shows that our methods converge in norm \eqref{eq:preferreddecomp}.

\begin{example}  \label{example:ball}  Consider the ``ball'' classical obstacle problem shown in Figure \ref{fig:ball} and Figure \ref{fig:activesizes} (middle), which has a known exact solution \cite[Chapter 12]{Bueler2021}.  Algorithms \ref{alg:udo} (UDO) and \ref{alg:vcd} (VCD) were applied to this problem, combined with inactive-set marking based on the BR error estimator \eqref{eq:brestimator}.  These methods, denoted UDO$+$BR and VCD$+$BR, avoid refinement in the active set, except near the estimated free boundary.  We also applied mesh adaptation Algorithm \ref{alg:avm} (AVM), setting mesh complexity targets to closely-match the number of elements from the other Algorithms; note that AVM refines everywhere.  The experiment started from a coarse uniform mesh over the square domain, and applied 11 levels of AMR, so that the number of elements increased by four orders of magnitude.  We also compared uniform refinement.

As shown in Figure \ref{fig:jaccball}, our AMR methods are clearly superior to uniform refinement when evaluated by active set Jaccard distances $d(A_u^h,A_u)$.  At higher resolutions, all three AMR methods reduce this distance an order of magnitude below uniform refinement.  While AVM produces the best meshes by this measure, its runtime is about an order of magnitude higher at comparable mesh complexity (not shown).

% see examples/sphere.py and genfigs/ballconv.py for these runs
\begin{figure}[ht]
\centering
\includegraphics[width=0.51\textwidth]{genfigs/jaccball.png}
\caption{Active set Jaccard distances $d(A_u^h,A_u)$.}
\label{fig:jaccball}
\end{figure}

On the other hand, Figure \ref{fig:ballconv} (left) shows that $L^2$ convergence using the standard error norm $\|u-u_h\|_2$ stagnates for the UDO$+$BR method.  This is entirely due to the contribution from the active set, i.e.~from $|\psi(x) - \psi_h(x)|$ for $x\in A_u^h$, over meshes which have \emph{deliberately} not been refined in $A_u^h$.  If we compute the $L^2$ error relative to the preferred approximation for the same meshes, namely $\|u-\tilde u_h\|_2$ as in \eqref{eq:preferreddecomp}, then the convergence is better than from uniform refinement, in a per-element sense.  Results from VCD$+$BR are virtually identical, and thus not shown.

As shown in Figure \ref{fig:ballconv} (right) for the AVM algorithm, because of its active set refinement, standard ($\|u-u_h\|_2$) and preferred ($\|u-\tilde u_h\|_2$) error norms are comparable. \end{example}

% see examples/sphere.py and genfigs/ballconv.py for these runs
\begin{figure}[ht]
\noindent\mbox{\includegraphics[width=0.48\textwidth]{genfigs/convball_UDO+BR.png} \, \includegraphics[width=0.48\textwidth]{genfigs/convball_AVM.png}}
\caption{Left: $L^2$ norm errors for the UDO$+$BR method, versus uniform refinement.  Right: The same norm errors for the AVM method.}
\label{fig:ballconv}
\end{figure}

To illustrate some additional mesh and performance features of our AMR approaches, we consider three more classical obstacle problem examples.  These do not have known exact solutions.

\begin{example}  \label{example:spiral}  Consider the spiral example on $\Omega=(-1,1)^2$ from \cite[subsection 7.1.1]{GraeserKornhuber2009}, shown in Figure \ref{fig:activesizes} (left).  This example  has source term $f=0$, homogeneous boundary values $g=0$, and a nontrivial obstacle $\psi$.  The active set is small in area while the free boundary is long.  A result from applying the UDO$+$BR approach is shown in Figure \ref{fig:spiralmesh}.  (Results from VCD$+$BR and AVM approaches are very similar and not shown.)  The free boundary is well-resolved, but there is no performance advantage from avoiding refinement in such a small active set. \end{example}

% generated from examples/spiral.py at levels=7
\begin{figure}[ht]
\centering
\includegraphics[height=60mm]{static/spiralmesh.png}
\caption{A refined mesh for Example \ref{example:spiral}, with $2\times 10^5$ elements, from seven levels of the UDO$+$BR approach, starting from an initial uniform mesh of 200 elements.  Element diameter (resolution) is $h\approx 10^{-3}$ along the free boundary.}
\label{fig:spiralmesh}
\end{figure}

\begin{example}  \label{example:blisters}   Consider the example shown in Figure \ref{fig:activesizes} (right), which has a large active set.  Here $\Omega=(0,1)^2$ and $\psi = g = 0$ in \eqref{eq:classical:vi}.  The source term $f$ is a sum of small-variance gaussian peaks against a negative background value; see the code for details.  The blistering property (Appendix \ref{app:blistering}) applies, so inactive set components necessarily include a $f>0$ portion.  The inactive set has six connected components, but this is only revealed at high resolution.  Figure \ref{fig:blistersmesh} shows the result of applying the VCD$+$BR method, giving a mesh with 100 times fewer elements than a uniform mesh with the same free-boundary resolution.  Similar to the glacier example in the next Section, in this case the avoidance of active-set refinement gives a distinct performance advantage.  The result from UDO$+$BR is very similar, and not shown. \end{example}

% generated from examples/blisters.py at levels=4
\begin{figure}[ht]
\centering
\mbox{
\includegraphics[height=60mm]{static/blistersmesh.png} \quad
\includegraphics[height=60mm]{static/blisterszoomed.png}
}
\caption{Left: A mesh for Example \ref{example:blisters} of $4.7\times 10^5$ elements, with resolution $h\approx 10^{-3}$ along the free boundary, from four levels of the VCD$+$BR approach, starting from a uniform mesh of 1800 elements.  Right: Zooming-in reveals inactive-set refinement, and separation of components.}
\label{fig:blistersmesh}
\end{figure}

\begin{example}  \label{example:lshaped}  Our third example is a free-boundary variation of the classic L-shaped Laplace equation problem with an interior corner.  Here the obstacle $\psi$ is the upper unit hemisphere, centered at the origin, and the domain is $\Omega = (-2,5)^2 \setminus S$ where $S$ is a $3\times 3$ square in the lower right corner.  Since $f=0$ and $g=-1$, the Laplace equation is solved in the inactive set, with unbounded solution Hessian in the interior corner.  A result from the VCD$+$BR algorithm, starting from a coarse unstructured mesh, is shown in Figure \ref{fig:lshapedmesh}.  (Again the other methods produce similar results.)  Though the exact free boundary is not known, it resolves into a smooth and nearly-circular curve.  At the same time there is refinement in the interior corner.  This example shows that free-boundary localization and classical PDE refinement goals are simultaneously addressed. \end{example}

% figure generated from meshfigs/lshaped.pvd
\begin{figure}[ht]
\centering
\includegraphics[height=62mm]{static/lshaped.png}
\caption{A refined mesh from five levels of the VCD$+$BR algorithm on Example \ref{example:lshaped}, showing a well-resolved free boundary and refinement in the interior corner.}
\label{fig:lshapedmesh}
\end{figure}


\section{Application to determining glaciated land areas} \label{sec:app}

In this section we apply our AMR techniques to a model for the steady geometry of a glacier, over a given bedrock topography and subject to a given climate.  In particular, this model solves for which land is covered by ice.  Though glacier ice will cover any land on which snowfall exceeds melt, ice flow expands the glaciated area out to a free boundary, the glacier margin, which can only be found from conservation equations.  Any fluid layer subject to surface processes which add or remove mass is governed by a related model \cite{Bueler2021b}.  In these VI problems, which generally are \emph{not} of optimization type, the unknown fluid thickness must be nonnegative, the operator is nonlinear, and the blistering property (Appendix \ref{app:blistering}) applies.

Let $\Omega \subset \RR^2$ be a fixed land region, with bedrock elevation $b=b(x,y) \in C^1(\Omega)$.  Assume there is a surface mass-balance \cite{GreveBlatter2009} function $a:\Omega \times \RR \to \RR$.  This climatic function models the annually-averaged rate of ice accumulation (snow) minus melt and runoff.  If $a$ depends on the surface elevation $s$ then we suppose that $a(x,y,s)\in L^\infty(\Omega)$ for any $s=s(x,y) \in L^\infty(\Omega)$, and additionally that $a$ is Lipschitz continuous in $s$.

We use an ice flow approximation called the \emph{shallow ice approximation} \cite{GreveBlatter2009}, derived by a thin-layer argument from mass and momentum conservation, in its simplest isothermal and non-sliding case.  Applying the standard exponent for the shear-thinning flow law of ice \cite{GreveBlatter2009}, we have a VI for admissible transformed ice thickness functions $u \in \cK = \{u \in \cX\,:\,u\ge 0 \text{ and } u|_{\partial\Omega}=0\}$, in the Banach space $\cX = W^{1,4}(\Omega)$ \cite{JouvetBueler2012}.  The thickness itself is $H=u^{3/8}$, while the surface elevation is $s=H+b=u^{3/8}+b$.  The model is a VI based upon a ``tilted'' variation of the $p$-Laplacian operator \cite{JouvetBueler2012}:
\begin{equation}
\int_\Omega \Gamma |\grad u + \bm{\beta}(u)|^2 (\grad u + \bm{\beta}(u)) \cdot \grad (v-u) - \tilde a(u) (v-u)\,dx \ge 0 \label{eq:sia:vi}
\end{equation}
for all $v \in \cK$.  Here $\Gamma>0$ is an ice softness constant, $\bm{\beta}(u)=\frac{8}{3} u^{5/8} \grad b$ is a nonlinear multiple of the bed gradient, and $\tilde a(u)=a(x,y,u^{3/8}+b(x,y))$ denotes the surface mass balance (with $x,y$ dependence suppressed).  When $\grad b=0$, \eqref{eq:sia:vi} defines a nonlinear operator $F(v)[w]$ which is $4$-coercive \cite{JouvetBueler2012}; recall definition \eqref{eq:coercive}.  If $a$ has no $s$ dependence then one may treat it as the source term, and write ``$F(u)[v-u]\ge\ell[v-u]$'' as in \eqref{eq:vi}, but otherwise we simply set $\ell=0$ in \eqref{eq:vi}.

Regarding the mathematical theory of \eqref{eq:sia:vi}, existence holds for any $b$ when $a$ is independent of $s$ \cite{JouvetBueler2012}.  Simple cases of \emph{non}-existence are known wherein $a$ depends on $s$ \cite{Jouvetetal2011}, but our examples below have slow increase of snowfall with elevation \cite{GreveBlatter2009}, which avoids the issue.

The strong-form interior condition for \eqref{eq:sia:vi} is a conservation equation:
\begin{equation}
\Div \bq = \tilde a \text{ over } I_u, \quad \text{where } \bq = - \Gamma |\grad u + \bm{\beta}(u)|^2 (\grad u + \bm{\beta}(u)).
\label{eq:sia:interior}
\end{equation}
At the free boundary (glacier margin) the solution $u$, the solution gradient $|\grad u|$, and the flux $\bq$ all go to zero.  On the other hand, observations confirm that the gradient of a glacier's surface has large magnitude as one approaches the margin from the ice side, a property which emerges from \eqref{eq:sia:vi} when one differentiates the associated surface elevation $s=u^{3/8} + b$, and in fact generally $|\grad s| \to \infty$ at the glacier margin.

We apply a conforming, continuous, piecewise-linear FE method \eqref{eq:fe:vi}, over unstructured triangulations.  The FE problem is either solved directly by the same VI-adapted Newton solver (\texttt{vinewtonrsls} in PETSc \cite{petsc-user-ref}) used in Section \ref{sec:results}, or with an added outer Picard-type iteration over the tilt $\bm{\beta}(u)$ \cite{JouvetBueler2012} and source $\tilde a(u)$, with Newton as the inner iteration.  The linear Newton steps are solved directly.  Very similar results are obtained when both converge, but the Picard-based solver is more robust when $|\grad b|$ is large or $\tilde a$ depends on $u$.

We consider two particular problems, each over a square domain $\Omega=(0,L)^2$, $L=1800$ kilometers.  The first ``dome'' problem has a flat bed, elevation-independent source, and a known exact solution \cite{Bueler2016}; this is used for verification and to compare AMR algorithms.  The second ``realistic'' problem has a bumpy bed and an elevation-dependent surface mass balance function.

\begin{example} \label{example:dome}
The dome problem was solved with 13 levels of refinement from an initial, uniform $h_0=360$ kilometer mesh to a final mesh with glacier margin resolution of $h_{13}\approx 30$ meters.  Both UDO and VCD methods (Section \ref{sec:viamr}) were applied, with GR marking in the inactive set (Section \ref{sec:inactive}).  Because the obstacle is $\psi=0$, the preferred and standard numerical solutions agree (see \eqref{eq:preferredapprox}), and numerical errors can be computed in the usual manner.  Figure \ref{fig:domenormresults} shows relative $H^1$ errors in the solution ($\|u-u_h\|_{H^1}/\|u\|_{H^1}$) and absolute $L^\infty$ errors in the corresponding ice thickness ($\|H-H_h\|_{L^\infty}$), versus number of elements.  The latter errors are much more responsive to AMR because the physical ice thickness gradient is singular at the free boundary, so (lateral) margin location error is effectively being measured.  Figure \ref{fig:domeradiusresults} shows the maximum radial error for the numerical margin, illustrating the free-boundary localization for the same runs.  We see that AMR methods are much more efficient for this purpose, compared to uniform refinement, similarly to the ball problem result in Section \ref{sec:results}, and again that the UDO and VCD variants perform very similarly.
\end{example}

% see examples/glacier/README.md for these runs
\begin{figure}[ht]
\noindent\mbox{\includegraphics[width=0.48\textwidth]{genfigs/uerrh1.png} \, \includegraphics[width=0.48\textwidth]{genfigs/herrinf.png}}
\caption{Left: $H^1$ norm errors in $u$ are comparable for AMR and uniform refinement, in a per-element sense.  Right: AMR is effective for the maximum thickness error.}
\label{fig:domenormresults}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.51\textwidth]{genfigs/drmax.png}
\caption{AMR generates accurate free boundary locations.  To achieve tens of meters accuracy, as here, uniform refinement would use orders of magnitude more elements.}
\label{fig:domeradiusresults}
\end{figure}

\begin{example} \label{example:realistic}
The next example is more realistic.  It uses a bumpy bedrock topography $b(x,y)$, a finite sum of sinusoids \cite[Example 8.4]{BuelerFarrell2024}, and a surface mass balance function $a(s)$ which depends only on surface elevation.\footnote{See the source code in \href{https://github.com/StefanoFochesatto/VI-AMR/examples/glacier/}{{\scriptsize \texttt{github.com/StefanoFochesatto/VI-AMR/examples/glacier/}}}.}  An important parameter in the formula for $a(s)$ is the equilibrium line altitude (ELA) \cite{GreveBlatter2009}, with $a>0$ above this altitude and $a< 0$ below.  Figure \ref{fig:transect} shows the topography along a transect $x=\hat x$ (red line in Figure \ref{fig:glacier}), with three ELA values $s_0$ superimposed.  Bedrock above the ELA will certainly be glacier-covered, but snowfall occurs on a larger solution-dependent set, namely $S=\{(x,y)\,:\,u(x,y)^{3/8} + b(x,y) > s_0\}$, and glaciation extends beyond $S$ because of flow: $I_u \supset S$.  The difficult nonlinearities in model \eqref{eq:sia:vi} include this elevation-dependent surface mass balance, but also the $u^{5/8}$ dependence in the tilt $\bm{\beta}(u)$.  Among the other effects of the latter nonlinearity is the tendency of ice to pool in bedrock elevation lows.

\begin{figure}[ht]
\centering
\medskip

\includegraphics[width=0.9\textwidth]{genfigs/transect.png}
\caption{Bedrock elevation (solid) along a transect (red in Figure \ref{fig:glacier}, left), with three ELA levels (dashed).}
\label{fig:transect}
\end{figure}

Our primary goals in this example are to generate an accurate map of glaciation, i.e.~of the inactive set $I_u$, to estimate the location of the glacier margin ($\Gamma_u$), and to compute the ice volume $V=\int_\Omega u^{3/8}\,dx\,dy$.  Note that the number of connected components of $I_u$, i.e.~the number of glaciers, is also a model output.

We applied UDO (Algorithm \ref{alg:udo}), with $n=2$ levels, and GR marking in the inactive set.  A minimum element diameter $\hmin=500$ meters (Section \ref{sec:viamr}) was set, with the resulting meshes having about 300 meter resolution along most of the glacier margin.  For ELA values $s_0=1000,800,600$ meters, the resulting surface elevation maps are shown in Figure \ref{fig:glacier}.  The varying ice volumes, $1.1\times 10^5$, $5.6\times 10^5$, and $8.9\times 10^5$ cubic kilometers, respectively, reflect the strong climate (ELA) sensitivity  of realistic glacier models \cite{GreveBlatter2009}.\footnote{Compare the volume of the present-day Greenland ice sheet at $2.9\times 10^6$ cubic kilometers.}

% see examples/glacier/{steady.py|caps.sh} for information about these runs
\begin{figure}[ht]
\centering

\mbox{\includegraphics[width=0.32\textwidth]{static/glacier/surf1000.png} \,\includegraphics[width=0.32\textwidth]{static/glacier/surf800.png} \,\includegraphics[width=0.32\textwidth]{static/glacier/surf600.png}}
\caption{Glacier surface elevation (grayscale) for ELA of 1000 meters (left), 800 meters (middle), and 600 meters (right).  Inset boxes are 200 km across; see Figure \ref{fig:insetmeshes}.}
\label{fig:glacier}
\end{figure}

Figure \ref{fig:insetmeshes} shows details of the resulting meshes along sample portions of the glacier margins.  It is key to observe that under the UDO$+$GR AMR approach the mesh was \emph{not} refined in the vast majority of the active set, and this represents a significant efficiency.  That is, we did not waste computational effort (e.g.~elements) on modeling ice which turned out to not be present.  Also we observe that this highly-nonlinear problem causes AMR to work hard to pin down the glacier margin, as only once the inactive side of the margin is resolved at high resolution will its location stabilize.
\begin{figure}[ht]
\centering
\mbox{\includegraphics[width=0.32\textwidth]{static/glacier/sub1000.png} \,\includegraphics[width=0.32\textwidth]{static/glacier/sub800.png} \,\includegraphics[width=0.32\textwidth]{static/glacier/sub600.png}}
\caption{Details of refined meshes (red) along glacier margins, from the inset boxes in Figure \ref{fig:glacier}, for the same ELA values.  The dark areas are coarsely-meshed ice-free areas, i.e.~active sets.}
\label{fig:insetmeshes}
\end{figure}
\end{example}


\section{Discussion} \label{sec:discussion}

It is well-known that inequality-constrained obstacle problems are intrinsically nonlinear, thus that solution methods must be iterative.  At a basic level our AMR methods simply extend this mandatory iteration idea to the generation of sequences of well-adapted unstructured meshes.  The UDO and VCD Algorithms from Section \ref{sec:viamr}, when applied in practice, combine two specific tagging strategies based \emph{a posteriori} on the numerical solution $u_h$ in simple ways:

\smallskip
\begin{enumerate}
\item assuming $u_h$ and $\psi_h$ imply an estimate of the true free boundary $\Gamma_u$, mark nearby elements on both sides of the computed free boundary $\Gamma_u^h$, and
\item assuming $u_h$ approximates the true solution $u$ in the computed inactive set $I_u^h$, mark elements in this set using PDE-type error estimates (Section \ref{sec:inactive}).
\end{enumerate}

\smallskip
\noindent The third , AVM Algorithm \ref{alg:avm}, generates a metric according to the same essential heuristics, allowing mesh adaptation.

Observe that \emph{i)} has nothing directly to do with the regularity or residual of $u_h$; refinement is geometrical in the domain.  Also note that \emph{ii)} could be done methods of arbitrary sophistication, specifically including dual weighted residual methods \cite{BangerthRannacher2003,Suttmeier2008}.  However, the weights in these methods are incapable of communicating information between disconnected components of the inactive set, the number and geometry of which is only found at solution time; Example \ref{example:blisters} shows this.

For classical obstacle problems, the mesh sequences built by our AMR techniques allow the bulk of the Newton iterations to occur inexpensively on the coarse early meshes. However, for harder problems, specifically the glaciation obstacle problem in Section \ref{sec:app}, the solver and AMR components nontrivially interact.  Nontrivial solver iterations are needed on intermediate meshes, to find and stabilize the free boundary.

Our AMR strategies are tied to the \emph{a priori} theory in Section \ref{sec:vifem}.  On the other hand, we have no direct, quantitative theory of how they reduce numerical error.

An important extension of our work would be to find effective refinement strategies for time-dependent obstacle problems and parabolic VI problems.  Also, performance could be improved by combining AMR with a multilevel solver approach, but this is also for future research.  The solver in \cite{BuelerFarrell2024} uses coarse meshes to make large corrections inside the solver, including geometrically to the free boundary.  Combining this solver with AMR promises highly-scalable solutions of difficult obstacle problems.

%\section*{Acknowledgements}


\bibliographystyle{siamplain}
\bibliography{viamr}


\appendix
\section{Obstacle problems with the blistering property} \label{app:blistering}

In a classical, unilateral obstacle problem \eqref{eq:classical:vi} an upward force $f(x)>0$ may occur in the active set $A_u$.  Physically speaking, in such a case the upward force was insufficient to lift $u$ off the obstacle $\psi$.  However, in certain problems this situation cannot occur.  The hypotheses of Lemma \ref{lem:blister} hold for classical problems \eqref{eq:classical:vi} when $\psi=0$, for the porous dam saturation free-boundary problem \cite[for example]{AinsworthOdenLee1993}, and for the glacier problem in Section \ref{sec:app}.

\begin{lemma} \label{lem:blister}
Suppose that $\psi=0$ and $\ell[v] = \int_\Omega fv\,dx$ for $f\in L^2(\Omega)$.  Suppose also that the operator $F$ is given by measurable densities,
\begin{equation} \label{eq:densitiesform}
F(w)[v] = \int_\Omega \phi(w(x),\grad w(x)) v(x) + \Phi(w(x),\grad w(x)) \cdot \grad v(x)\,dx,
\end{equation}
satisfying $\phi(0,0)=0$ and $\Phi(0,0)=0$.  Then for $u$ solving VI \eqref{eq:vi}, $f\le 0$ a.e.~in $A_u$.
\end{lemma}

\begin{proof}
Let $S\subset A_u$ be a Borel set, and denote its indicator function by $\chi_S \in L^\infty(\Omega)$.  By a density argument and the assumptions on $\phi$ and $\Phi$, the operator value $F(u)[\chi_S]$ is well-defined, \emph{and zero}, because $S$ is in the active set.  Thus by Lemma \ref{lem:measure},
\begin{equation*}
0 \le d\mu_u(S) = F(u)[\chi_S]-\ell[\chi_S] = 0 - \ell[\chi_S] = -\int_S f\,dx.
\end{equation*}
This shows $f\le 0$ a.e.~with respect to Lebesgue measure.
\end{proof}

\begin{definition}
For a unilateral obstacle problem \eqref{eq:vi} with source term $\ell[v] = \int_\Omega fv\,dx$ and $f\in C(\bar \Omega)$, we say that the \emph{blistering property} holds if $A_u \subset \{x \in \Omega\, :\, f(x)\le 0\}$ \cite{JouvetBueler2012}, that is, if the conclusion of Lemma \ref{lem:blister} holds.
\end{definition}

To explain the language, if $f(x)>0$ for some $x\in\Omega$ then, assuming this property, the inactive set $I_u$ must be non-empty, and $x\in I_u$.  That is, even a small upward force ``blisters'' the membrane off the obstacle.

Any classical problem \eqref{eq:classical:vi} with a smooth obstacle $\psi\in C^2(\bar\Omega)$ can be transformed into one with the blistering property.  Let $\tilde v=v-\psi$, thus $\tilde\cK = \{\tilde v\in\cX\,:\,\tilde v\ge 0 \text{ and } \tilde v|_{\partial\Omega}=g-\psi|_{\partial\Omega}\}$.  Integration-by-parts shows \eqref{eq:classical:vi} is equivalent to finding $\tilde u = u -\psi \in \tilde \cK$ so that
\begin{equation} \label{eq:classical:vi:blister}
\int_\Omega \nabla \tilde u \cdot \nabla(\tilde v - \tilde u) \ge \int_\Omega \left(f+\grad^2\psi\right)(\tilde v - \tilde u) \quad \text{ for all } \tilde v \in \tilde \cK.
\end{equation}
For VI problem \eqref{eq:classical:vi:blister}, if $x\in A_{\tilde u} = \{\tilde u(x)=0\}$ then $\tilde f(x)= f(x)+\grad^2\psi(x)\le 0$.

For blistering-property problems, AMR costs can be reduced by systematically avoiding refinement in the computed active sets.  From a computed solution $u_h$, one identifies elements $K\in \cT_h$ such that $K \subset A_u^h$.  (In our implementation we require that every node in the closure of $K$ is active, according to some tolerance.)  The degenerate case must be excluded, so we also require $K \subset \Omega_- = \{x\in \Omega\,:\,f(x) < 0\}$; note this uses only the data of the problem.  Then for $K\subset \Omega_- \cap A_u^h$ no refinement is needed \emph{if} $K$ is geometrically far from the free boundary.  However, if later refinements move the free boundary to be incident to $K$ then refinement of $K$ becomes appropriate.

\end{document}
